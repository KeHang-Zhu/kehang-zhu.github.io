---
permalink: /
title: "About"
# excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html

---

Hello there! I'm Kehang.

I'm a final year Ph.D. candidate at Harvard University. I've been jointly advised by [Prof. John Horton](https://mitsloan.mit.edu/faculty/directory/john-j-horton) from [MIT Sloan's IT group](https://mitsloan.mit.edu/faculty/academic-groups/information-technology/faculty-research-centers) and [Prof. David Parkes](https://parkes.seas.harvard.edu/) from Harvard's [EconCS group](https://econcs.seas.harvard.edu/). 
I had the pleasure to intern in [Google DeepMind](https://deepmind.google/) and worked with Crystal Qian, Nithum Thain and James Wexler.


I study **AI agents** as proxies for human decision-making and how individuals collaborate with these agents in economic environments.

My research has two primary strands.
- First, I examine the capabilities, benefits, and trade-offs of deploying large language models (LLMs) as autonomous agents. I develop novel AI tools and run large-scale economic experiments to understand when and how LLM agents replicate, augment, or diverge from human behavior.

- Second, I use LLM-based simulations to uncover new patterns in human decision-making and to design more effective interventions, market mechanisms, and organizational policies. By combining computational modeling with experimental economics, my work aims to inform the responsible deployment of AI in markets and institutions.

<!-- The central problem I aim to address is how to make **mechanism design** more applicable in real-world scenarios. Many theoretically optimal mechanisms are seldom applied in practice due to their complexity.

My work focuses on using Large Language Models (LLMs) as **Proxies** for Human behaviors in traditional lab experiments. People can express their intentions in natural language, and an LLM agent will act as their proxy within the mechanism. -->


<!-- I am generally interested in modelling human behaviors and mechanism design.

In the short term,, I am exploring these two directions:
1. Do Language Models (LMs) behave like Humans?
2. Are predictions made on LMs valid on Humans? 

Looking ahead, my long-term scope concerning two questions:
1. How to better model Human Behaviors with AI?
2. How to increase the Welfare of Human Being with AI modeling? -->

## My Research

**[Automated Social Science: Language Models as Scientist and Subjects](https://arxiv.org/abs/2404.11794)**

<sub>With Benjamin Manning* and John Horton .</sub>

<sub>Reject and Resubmit at the Quarterly Journal of Economics.</sub>

<sub> Selected Media: [Marginal revolution](https://marginalrevolution.com/marginalrevolution/2024/03/its-happening-economic-science-edition.html), [The Future of Being Human](https://futureofbeinghuman.com/p/can-ai-be-used-to-automate-social), [One Useful Thing](https://www.oneusefulthing.org/p/four-singularities-for-research),  </sub>

**[Strategic Tradeoffs Between Human and AI Agents in Bargaining Games](https://arxiv.org/pdf/2509.09071)**

<sub>With Google DeepMind Team: Crystal Qian*, Vivian Tsai, James Wexler, Nithum Thain and John Horton, Benjamin Manning</sub>

<sub>Accepted in IUI 2026</sub>

<sub>[Featured Research by Prolific](https://www.prolific.com/resources/how-google-deepmind-is-advancing-multi-party-ai-research-with-deliberate-lab)</sub>

<!-- [AI Breakfast](https://aibreakfast.beehiiv.com/p/llmbased-system-designs-runs-social-experiments),  -->
<!-- [AI in Education](https://www.linkedin.com/pulse/ai-education-new-research-6th-may-ray-fleming-h7xge/) -->
<!-- [LLM in Science](https://llminscience.com/),  -->

**[Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation](https://arxiv.org/abs/2602.12089)**

<sub>Intern work in Google DeepMind, with Nithum Thain, Vivian Tsai, James Wexler, Crystal Qian</sub>

**[Learning from Synthetic Laboratory: Language Models as Auction Participants](https://arxiv.org/pdf/2507.09083?)**

<sub>With Anand Shah*, Jeffery Wang, Arif K. Dayi, Yanchen Jiang, John Horton and David Parkes</sub>

<sub>NeurIPS 2024 (Workshop), EC 2024 (Poster)</sub>


<!-- Don't hesitate to email me if you are interested in research opportunities or want to collaborate. I constantly mentor undergrad and grad students from Harvard, MIT and other schools. -->

## My Journey So Far

Before joining Harvard, I was very lucky, undeservedly so, to be host by Nobel Laureate in Physics [Prof. Frank Wilczek](https://physics.mit.edu/faculty/frank-wilczek/) in MIT. I was working on using Quantum field theory to model correlated dynamics inside a class of material (quantum spin ice) [News](https://meetings.aps.org/Meeting/MAR22/Session/K51.5).

My research interests turned to human and society after an enriching collaboration with [Prof. Hanspeter Pfister](https://seas.harvard.edu/person/hanspeter-pfister) from Harvard [Viusal Computing Group](https://vcg.seas.harvard.edu/). I ran large-scale human-subject studies to investigate the mental models of people making sense of visualizations [CHI 24'](https://programs.sigchi.org/chi/2024/program/content/147374). 
[**Reading Between the Pixels: Investigating the Barriers to Visualization Literacy**](/files/reading-between-pixels.pdf)

Recently, I was selected as the Introduction to Technical AI Safety Fellow with the [AI Safety Student Team](https://haist.ai/)


## A Pinch of Extra

When I'm not geeking out over research, you can find me capturing the world through my camera lens ðŸ“¸, embracing the beauty of nature ðŸŒ², hitting the ski slopes ðŸŽ¿, or trekking through scenic trails ðŸ¥¾.


## Selected Honors 
- Google DeepMind Seed Fund, 2024
- Introduction to Technical AI Safety Fellowship, 2023
- Purcell Fellowship (Harvard), 2021
- Guo Moruo Scholarship (Highest honor for USTC undergrad students), 2020 
- Yan Jici  Scholarship (Highest honor for Physics department undergrad students), 2020 


---

<!-- Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png) -->
